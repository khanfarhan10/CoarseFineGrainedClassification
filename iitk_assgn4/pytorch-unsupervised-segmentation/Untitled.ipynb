{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9e566cef4940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# slic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompactness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompactness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_superpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mu_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from skimage import segmentation\n",
    "import torch.nn.init\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Unsupervised Segmentation')\n",
    "parser.add_argument('--nChannel', metavar='N', default=100, type=int, \n",
    "                    help='number of channels')\n",
    "parser.add_argument('--maxIter', metavar='T', default=1000, type=int, \n",
    "                    help='number of maximum iterations')\n",
    "parser.add_argument('--minLabels', metavar='minL', default=3, type=int, \n",
    "                    help='minimum number of labels')\n",
    "parser.add_argument('--lr', metavar='LR', default=0.1, type=float, \n",
    "                    help='learning rate')\n",
    "parser.add_argument('--nConv', metavar='M', default=2, type=int, \n",
    "                    help='number of convolutional layers')\n",
    "parser.add_argument('--num_superpixels', metavar='K', default=10000, type=int, \n",
    "                    help='number of superpixels')\n",
    "parser.add_argument('--compactness', metavar='C', default=100, type=float, \n",
    "                    help='compactness of superpixels')\n",
    "parser.add_argument('--visualize', metavar='1 or 0', default=1, type=int, \n",
    "                    help='visualization flag')\n",
    "parser.add_argument('--input', metavar='FILENAME',\n",
    "                    help='input image file name', required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# CNN model\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, args.nChannel, kernel_size=3, stride=1, padding=1 )\n",
    "        self.bn1 = nn.BatchNorm2d(args.nChannel)\n",
    "        self.conv2 = []\n",
    "        self.bn2 = []\n",
    "        for i in range(args.nConv-1):\n",
    "            self.conv2.append( nn.Conv2d(args.nChannel, args.nChannel, kernel_size=3, stride=1, padding=1 ) )\n",
    "            self.bn2.append( nn.BatchNorm2d(args.nChannel) )\n",
    "        self.conv3 = nn.Conv2d(args.nChannel, args.nChannel, kernel_size=1, stride=1, padding=0 )\n",
    "        self.bn3 = nn.BatchNorm2d(args.nChannel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu( x )\n",
    "        x = self.bn1(x)\n",
    "        for i in range(args.nConv-1):\n",
    "            x = self.conv2[i](x)\n",
    "            x = F.relu( x )\n",
    "            x = self.bn2[i](x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x\n",
    "\n",
    "# load image\n",
    "# im = cv2.imread(args.input)\n",
    "im = cv2.imread(\"00004.jpg\")\n",
    "data = torch.from_numpy( np.array([im.transpose( (2, 0, 1) ).astype('float32')/255.]) )\n",
    "if use_cuda:\n",
    "    data = data.cuda()\n",
    "data = Variable(data)\n",
    "\n",
    "# slic\n",
    "labels = segmentation.slic(im, compactness=args.compactness, n_segments=args.num_superpixels)\n",
    "labels = labels.reshape(im.shape[0]*im.shape[1])\n",
    "u_labels = np.unique(labels)\n",
    "l_inds = []\n",
    "for i in range(len(u_labels)):\n",
    "    l_inds.append( np.where( labels == u_labels[ i ] )[ 0 ] )\n",
    "\n",
    "# train\n",
    "model = MyNet( data.size(1) )\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    for i in range(args.nConv-1):\n",
    "        model.conv2[i].cuda()\n",
    "        model.bn2[i].cuda()\n",
    "model.train()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "label_colours = np.random.randint(255,size=(100,3))\n",
    "for batch_idx in range(args.maxIter):\n",
    "    # forwarding\n",
    "    optimizer.zero_grad()\n",
    "    output = model( data )[ 0 ]\n",
    "    output = output.permute( 1, 2, 0 ).contiguous().view( -1, args.nChannel )\n",
    "    ignore, target = torch.max( output, 1 )\n",
    "    im_target = target.data.cpu().numpy()\n",
    "    nLabels = len(np.unique(im_target))\n",
    "    if args.visualize:\n",
    "        im_target_rgb = np.array([label_colours[ c % 100 ] for c in im_target])\n",
    "        im_target_rgb = im_target_rgb.reshape( im.shape ).astype( np.uint8 )\n",
    "        cv2.imshow( \"output\", im_target_rgb )\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "    # superpixel refinement\n",
    "    # TODO: use Torch Variable instead of numpy for faster calculation\n",
    "    for i in range(len(l_inds)):\n",
    "        labels_per_sp = im_target[ l_inds[ i ] ]\n",
    "        u_labels_per_sp = np.unique( labels_per_sp )\n",
    "        hist = np.zeros( len(u_labels_per_sp) )\n",
    "        for j in range(len(hist)):\n",
    "            hist[ j ] = len( np.where( labels_per_sp == u_labels_per_sp[ j ] )[ 0 ] )\n",
    "        im_target[ l_inds[ i ] ] = u_labels_per_sp[ np.argmax( hist ) ]\n",
    "    target = torch.from_numpy( im_target )\n",
    "    if use_cuda:\n",
    "        target = target.cuda()\n",
    "    target = Variable( target )\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print (batch_idx, '/', args.maxIter, ':', nLabels, loss.data[0])\n",
    "    if nLabels <= args.minLabels:\n",
    "        print (\"nLabels\", nLabels, \"reached minLabels\", args.minLabels, \".\")\n",
    "        break\n",
    "\n",
    "# save output image\n",
    "if not args.visualize:\n",
    "    output = model( data )[ 0 ]\n",
    "    output = output.permute( 1, 2, 0 ).contiguous().view( -1, args.nChannel )\n",
    "    ignore, target = torch.max( output, 1 )\n",
    "    im_target = target.data.cpu().numpy()\n",
    "    im_target_rgb = np.array([label_colours[ c % 100 ] for c in im_target])\n",
    "    im_target_rgb = im_target_rgb.reshape( im.shape ).astype( np.uint8 )\n",
    "cv2.imwrite( \"output.png\", im_target_rgb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
